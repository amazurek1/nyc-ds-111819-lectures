{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularization \n",
    "Agenda today:\n",
    "- Reviewing overfitting & underfitting, bias variance tradeoff\n",
    "- Ridge regression \n",
    "- Lasso regression \n",
    "- AIC and BIC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part I. Regularizing a Model\n",
    "Even though Lasso and Ridge regressions are only used in regression, regularizing a model is a common procedure in the process of building machine learning models. It is an effectuve procedure for tackling the problem of overfitting. Generally speaking, applying regularization technique introduces some **bias** to the model, but reduces the **variance**, and therefore results in better performance in testing data. As you will see later in this module, models built from various classification algorithms often require tuning using regularization in order to overcome overfitting. \n",
    "\n",
    "What is regularization in the context of regression? As we recall, as the complexity of model increases, the model overfits and performance on the testing set decreases. Regularization techniques *shrinks* the regression coefficients such that the coefficients are not affecting the outcomes as much as they originally would have. In other words, using regularization applies a *penalty* to the coefficients of your regression model. Let's see how exactly Ridge regression and Lasso regression work to reduce variances in regression models and result in better fit. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower some variance and put in bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#introduce bias to lower variance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/26ufdipQqU2lhNA4g/giphy.gif\" >"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part II. Ridge Regression (L2 Norm)\n",
    "Before we dive into regularization, let's (re)visit a concept called **Cost Function**. A cost function is a measure of how good or bad the model is at estimating the relationship of our $X$ and $y$ variables. Usually, it is expressed in the difference between actual values and predicted values. For simple linear regression, the cost function is represented as:\n",
    "<center> $$ \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum( bx + b_0))^2$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For linear regression with multiple predictors, the cost function is expressed as:\n",
    "$$ \\text{cost_function}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij} + b))^2$$\n",
    "\n",
    "Where k stands for number of predictors at jth term.\n",
    "\n",
    "The ridge regression applies a penalizing parameter $\\lambda$ *slope* $^2$, such that a small bias will be introduced to the entire model depending on the value of $\\lambda$, which is called a *hyperparameter*. \n",
    "\n",
    "$$ \\text{cost_function_ridge}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p m_j^2$$\n",
    "\n",
    "The result of applying such a penalizing parameter to the cost function, resulting a different regression model that minimizing the residual sum of square **and** the term $\\lambda \\sum_{j=1}^p m_j^2$. \n",
    "\n",
    "The Ridge regression improves the fit of the original regression line by introducing some bias/changing the slope and intercept of the original line. Recall the way we interpret a regression model Y = mx + b: with every unit increase in x, the outcome y increase by m unit. Therefore, the bigger the coefficient m is, the more the outcome is subjected to changes in predictor x. Ridge regression works by reducing the magnitude of the coefficient m and therefore reducing the effect the predictors have on the outcome. Let's look at a simple example.\n",
    "\n",
    "The ridge regression penalty term contains all of the coefficients squared from the original regression line except for the intercept term. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part III. Lasso Regression (L1 Norm)\n",
    "Lasso regression is very similar to Ridge regression except for one difference - the penalty term is not squared but the absolute values of the coefficients muliplied by lambda, expressed by:\n",
    "\n",
    "$$ \\text{cost_function_lasso}= \\sum_{i=1}^n(y_i - \\hat{y})^2 = \\sum_{i=1}^n(y_i - \\sum_{j=1}^k(m_jx_{ij} + b))^2 + \\lambda \\sum_{j=1}^p \\mid m_j \\mid$$\n",
    "\n",
    "The biggest difference in Ridge and Lasso is that Lasso simultaneously performs variable selection: some coefficients are shrunk to 0, rendering them nonexistence in the original regression model. Therefore, Lasso regression performs very well when you have higher dimensional dataset where some predictors are useless; whereas Ridge works best when all the predictors are needed. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"https://media.giphy.com/media/AWeYSE0qgpk76/giphy.gif\" width= \"400\" />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/preprocessing/data.py:323: DataConversionWarning: Data with input dtype int64, float64 were all converted to float64 by MinMaxScaler.\n",
      "  return self.partial_fit(X, y)\n"
     ]
    }
   ],
   "source": [
    "# implementation \n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import Lasso, Ridge, LinearRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "data = sns.load_dataset('mpg')\n",
    "\n",
    "#data = pd.read_csv(\"https://raw.githubusercontent.com/learn-co-curriculum/dsc-2-24-09-ridge-and-lasso-regression/master/auto-mpg.csv\") \n",
    "data = data.sample(50)\n",
    "y = data[[\"mpg\"]]\n",
    "X = data.drop([\"mpg\", \"name\", \"origin\"], axis=1)\n",
    "\n",
    "scale = MinMaxScaler()\n",
    "transformed = scale.fit_transform(X)\n",
    "X = pd.DataFrame(transformed, columns = X.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mpg</th>\n",
       "      <th>cylinders</th>\n",
       "      <th>displacement</th>\n",
       "      <th>horsepower</th>\n",
       "      <th>weight</th>\n",
       "      <th>acceleration</th>\n",
       "      <th>model_year</th>\n",
       "      <th>origin</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>222</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>260.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>4060</td>\n",
       "      <td>19.0</td>\n",
       "      <td>77</td>\n",
       "      <td>usa</td>\n",
       "      <td>oldsmobile cutlass supreme</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>97.0</td>\n",
       "      <td>2506</td>\n",
       "      <td>14.5</td>\n",
       "      <td>72</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyouta corona mark ii (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2228</td>\n",
       "      <td>14.0</td>\n",
       "      <td>71</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corona</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>344</th>\n",
       "      <td>39.0</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>64.0</td>\n",
       "      <td>1875</td>\n",
       "      <td>16.4</td>\n",
       "      <td>81</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth champ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>21.6</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>115.0</td>\n",
       "      <td>2795</td>\n",
       "      <td>15.7</td>\n",
       "      <td>78</td>\n",
       "      <td>europe</td>\n",
       "      <td>saab 99gle</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>382</th>\n",
       "      <td>34.0</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2245</td>\n",
       "      <td>16.9</td>\n",
       "      <td>82</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>78.0</td>\n",
       "      <td>3574</td>\n",
       "      <td>21.0</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford granada ghia</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>229</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>180.0</td>\n",
       "      <td>4220</td>\n",
       "      <td>11.1</td>\n",
       "      <td>77</td>\n",
       "      <td>usa</td>\n",
       "      <td>pontiac grand prix lj</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>12.0</td>\n",
       "      <td>8</td>\n",
       "      <td>400.0</td>\n",
       "      <td>167.0</td>\n",
       "      <td>4906</td>\n",
       "      <td>12.5</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>22.0</td>\n",
       "      <td>6</td>\n",
       "      <td>198.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2833</td>\n",
       "      <td>15.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth duster</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>66</th>\n",
       "      <td>17.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>150.0</td>\n",
       "      <td>3672</td>\n",
       "      <td>11.5</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc ambassador sst</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>166</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>3169</td>\n",
       "      <td>12.0</td>\n",
       "      <td>75</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford mustang ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>109</th>\n",
       "      <td>21.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>2401</td>\n",
       "      <td>19.5</td>\n",
       "      <td>73</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet vega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>132</th>\n",
       "      <td>25.0</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2542</td>\n",
       "      <td>17.0</td>\n",
       "      <td>74</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet vega</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>154</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>72.0</td>\n",
       "      <td>3432</td>\n",
       "      <td>21.0</td>\n",
       "      <td>75</td>\n",
       "      <td>usa</td>\n",
       "      <td>mercury monarch</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>294</th>\n",
       "      <td>34.1</td>\n",
       "      <td>4</td>\n",
       "      <td>86.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>15.2</td>\n",
       "      <td>79</td>\n",
       "      <td>japan</td>\n",
       "      <td>maxda glc deluxe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>221</th>\n",
       "      <td>17.5</td>\n",
       "      <td>8</td>\n",
       "      <td>305.0</td>\n",
       "      <td>145.0</td>\n",
       "      <td>3880</td>\n",
       "      <td>12.5</td>\n",
       "      <td>77</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet caprice classic</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>31.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>68.0</td>\n",
       "      <td>1970</td>\n",
       "      <td>17.6</td>\n",
       "      <td>82</td>\n",
       "      <td>japan</td>\n",
       "      <td>mazda glc custom</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>440.0</td>\n",
       "      <td>215.0</td>\n",
       "      <td>4312</td>\n",
       "      <td>8.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth fury iii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>24.0</td>\n",
       "      <td>4</td>\n",
       "      <td>113.0</td>\n",
       "      <td>95.0</td>\n",
       "      <td>2372</td>\n",
       "      <td>15.0</td>\n",
       "      <td>70</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corona mark ii</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>237</th>\n",
       "      <td>30.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>63.0</td>\n",
       "      <td>2051</td>\n",
       "      <td>17.0</td>\n",
       "      <td>77</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet chevette</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>135</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>225.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>3613</td>\n",
       "      <td>16.5</td>\n",
       "      <td>74</td>\n",
       "      <td>usa</td>\n",
       "      <td>plymouth satellite sebring</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>352</th>\n",
       "      <td>29.9</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>2380</td>\n",
       "      <td>20.7</td>\n",
       "      <td>81</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford escort 2h</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>455.0</td>\n",
       "      <td>225.0</td>\n",
       "      <td>3086</td>\n",
       "      <td>10.0</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>buick estate wagon (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>15.5</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>120.0</td>\n",
       "      <td>3962</td>\n",
       "      <td>13.9</td>\n",
       "      <td>76</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc matador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>263</th>\n",
       "      <td>17.7</td>\n",
       "      <td>6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>3445</td>\n",
       "      <td>13.4</td>\n",
       "      <td>78</td>\n",
       "      <td>usa</td>\n",
       "      <td>buick regal sport coupe (turbo)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>122.0</td>\n",
       "      <td>86.0</td>\n",
       "      <td>2395</td>\n",
       "      <td>16.0</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford pinto (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>282</th>\n",
       "      <td>22.3</td>\n",
       "      <td>4</td>\n",
       "      <td>140.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2890</td>\n",
       "      <td>17.3</td>\n",
       "      <td>79</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford fairmont 4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>351.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>4657</td>\n",
       "      <td>13.5</td>\n",
       "      <td>75</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford ltd</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>9.0</td>\n",
       "      <td>8</td>\n",
       "      <td>304.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>4732</td>\n",
       "      <td>18.5</td>\n",
       "      <td>70</td>\n",
       "      <td>usa</td>\n",
       "      <td>hi 1200d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>21.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>2979</td>\n",
       "      <td>19.5</td>\n",
       "      <td>72</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 504 (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>347</th>\n",
       "      <td>37.0</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>65.0</td>\n",
       "      <td>1975</td>\n",
       "      <td>19.4</td>\n",
       "      <td>81</td>\n",
       "      <td>japan</td>\n",
       "      <td>datsun 210 mpg</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>29.0</td>\n",
       "      <td>4</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1937</td>\n",
       "      <td>14.2</td>\n",
       "      <td>76</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>220</th>\n",
       "      <td>33.5</td>\n",
       "      <td>4</td>\n",
       "      <td>85.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>1945</td>\n",
       "      <td>16.8</td>\n",
       "      <td>77</td>\n",
       "      <td>japan</td>\n",
       "      <td>datsun f-10 hatchback</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>26.0</td>\n",
       "      <td>4</td>\n",
       "      <td>96.0</td>\n",
       "      <td>69.0</td>\n",
       "      <td>2189</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>europe</td>\n",
       "      <td>renault 12 (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>232.0</td>\n",
       "      <td>100.0</td>\n",
       "      <td>3288</td>\n",
       "      <td>15.5</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc matador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>79.0</td>\n",
       "      <td>70.0</td>\n",
       "      <td>2074</td>\n",
       "      <td>19.5</td>\n",
       "      <td>71</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 304</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>139</th>\n",
       "      <td>14.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4638</td>\n",
       "      <td>16.0</td>\n",
       "      <td>74</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford gran torino (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>361</th>\n",
       "      <td>25.4</td>\n",
       "      <td>6</td>\n",
       "      <td>168.0</td>\n",
       "      <td>116.0</td>\n",
       "      <td>2900</td>\n",
       "      <td>12.6</td>\n",
       "      <td>81</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota cressida</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>136</th>\n",
       "      <td>16.0</td>\n",
       "      <td>8</td>\n",
       "      <td>302.0</td>\n",
       "      <td>140.0</td>\n",
       "      <td>4141</td>\n",
       "      <td>14.0</td>\n",
       "      <td>74</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford gran torino</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>32.2</td>\n",
       "      <td>4</td>\n",
       "      <td>108.0</td>\n",
       "      <td>75.0</td>\n",
       "      <td>2265</td>\n",
       "      <td>15.2</td>\n",
       "      <td>80</td>\n",
       "      <td>japan</td>\n",
       "      <td>toyota corolla</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>41.5</td>\n",
       "      <td>4</td>\n",
       "      <td>98.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2144</td>\n",
       "      <td>14.7</td>\n",
       "      <td>80</td>\n",
       "      <td>europe</td>\n",
       "      <td>vw rabbit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>30.0</td>\n",
       "      <td>4</td>\n",
       "      <td>97.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>1985</td>\n",
       "      <td>16.4</td>\n",
       "      <td>77</td>\n",
       "      <td>japan</td>\n",
       "      <td>subaru dl</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>162</th>\n",
       "      <td>15.0</td>\n",
       "      <td>6</td>\n",
       "      <td>258.0</td>\n",
       "      <td>110.0</td>\n",
       "      <td>3730</td>\n",
       "      <td>19.0</td>\n",
       "      <td>75</td>\n",
       "      <td>usa</td>\n",
       "      <td>amc matador</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>258</th>\n",
       "      <td>20.6</td>\n",
       "      <td>6</td>\n",
       "      <td>231.0</td>\n",
       "      <td>105.0</td>\n",
       "      <td>3380</td>\n",
       "      <td>15.8</td>\n",
       "      <td>78</td>\n",
       "      <td>usa</td>\n",
       "      <td>buick century special</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>77</th>\n",
       "      <td>22.0</td>\n",
       "      <td>4</td>\n",
       "      <td>121.0</td>\n",
       "      <td>76.0</td>\n",
       "      <td>2511</td>\n",
       "      <td>18.0</td>\n",
       "      <td>72</td>\n",
       "      <td>europe</td>\n",
       "      <td>volkswagen 411 (sw)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>23.0</td>\n",
       "      <td>4</td>\n",
       "      <td>120.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>2957</td>\n",
       "      <td>17.0</td>\n",
       "      <td>75</td>\n",
       "      <td>europe</td>\n",
       "      <td>peugeot 504</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>33.0</td>\n",
       "      <td>4</td>\n",
       "      <td>91.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1795</td>\n",
       "      <td>17.5</td>\n",
       "      <td>75</td>\n",
       "      <td>japan</td>\n",
       "      <td>honda civic cvcc</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>62</th>\n",
       "      <td>13.0</td>\n",
       "      <td>8</td>\n",
       "      <td>350.0</td>\n",
       "      <td>165.0</td>\n",
       "      <td>4274</td>\n",
       "      <td>12.0</td>\n",
       "      <td>72</td>\n",
       "      <td>usa</td>\n",
       "      <td>chevrolet impala</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>18.0</td>\n",
       "      <td>6</td>\n",
       "      <td>250.0</td>\n",
       "      <td>88.0</td>\n",
       "      <td>3139</td>\n",
       "      <td>14.5</td>\n",
       "      <td>71</td>\n",
       "      <td>usa</td>\n",
       "      <td>ford mustang</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      mpg  cylinders  displacement  horsepower  weight  acceleration  \\\n",
       "222  17.0          8         260.0       110.0    4060          19.0   \n",
       "82   23.0          4         120.0        97.0    2506          14.5   \n",
       "31   25.0          4         113.0        95.0    2228          14.0   \n",
       "344  39.0          4          86.0        64.0    1875          16.4   \n",
       "276  21.6          4         121.0       115.0    2795          15.7   \n",
       "382  34.0          4         108.0        70.0    2245          16.9   \n",
       "200  18.0          6         250.0        78.0    3574          21.0   \n",
       "229  16.0          8         400.0       180.0    4220          11.1   \n",
       "104  12.0          8         400.0       167.0    4906          12.5   \n",
       "15   22.0          6         198.0        95.0    2833          15.5   \n",
       "66   17.0          8         304.0       150.0    3672          11.5   \n",
       "166  13.0          8         302.0       129.0    3169          12.0   \n",
       "109  21.0          4         140.0        72.0    2401          19.5   \n",
       "132  25.0          4         140.0        75.0    2542          17.0   \n",
       "154  15.0          6         250.0        72.0    3432          21.0   \n",
       "294  34.1          4          86.0        65.0    1975          15.2   \n",
       "221  17.5          8         305.0       145.0    3880          12.5   \n",
       "377  31.0          4          91.0        68.0    1970          17.6   \n",
       "7    14.0          8         440.0       215.0    4312           8.5   \n",
       "14   24.0          4         113.0        95.0    2372          15.0   \n",
       "237  30.5          4          98.0        63.0    2051          17.0   \n",
       "135  18.0          6         225.0       105.0    3613          16.5   \n",
       "352  29.9          4          98.0        65.0    2380          20.7   \n",
       "13   14.0          8         455.0       225.0    3086          10.0   \n",
       "189  15.5          8         304.0       120.0    3962          13.9   \n",
       "263  17.7          6         231.0       165.0    3445          13.4   \n",
       "80   22.0          4         122.0        86.0    2395          16.0   \n",
       "282  22.3          4         140.0        88.0    2890          17.3   \n",
       "159  14.0          8         351.0       148.0    4657          13.5   \n",
       "28    9.0          8         304.0       193.0    4732          18.5   \n",
       "78   21.0          4         120.0        87.0    2979          19.5   \n",
       "347  37.0          4          85.0        65.0    1975          19.4   \n",
       "197  29.0          4          90.0        70.0    1937          14.2   \n",
       "220  33.5          4          85.0        70.0    1945          16.8   \n",
       "79   26.0          4          96.0        69.0    2189          18.0   \n",
       "37   18.0          6         232.0       100.0    3288          15.5   \n",
       "51   30.0          4          79.0        70.0    2074          19.5   \n",
       "139  14.0          8         302.0       140.0    4638          16.0   \n",
       "361  25.4          6         168.0       116.0    2900          12.6   \n",
       "136  16.0          8         302.0       140.0    4141          14.0   \n",
       "321  32.2          4         108.0        75.0    2265          15.2   \n",
       "309  41.5          4          98.0        76.0    2144          14.7   \n",
       "239  30.0          4          97.0        67.0    1985          16.4   \n",
       "162  15.0          6         258.0       110.0    3730          19.0   \n",
       "258  20.6          6         231.0       105.0    3380          15.8   \n",
       "77   22.0          4         121.0        76.0    2511          18.0   \n",
       "178  23.0          4         120.0        88.0    2957          17.0   \n",
       "181  33.0          4          91.0        53.0    1795          17.5   \n",
       "62   13.0          8         350.0       165.0    4274          12.0   \n",
       "48   18.0          6         250.0        88.0    3139          14.5   \n",
       "\n",
       "     model_year  origin                             name  \n",
       "222          77     usa       oldsmobile cutlass supreme  \n",
       "82           72   japan      toyouta corona mark ii (sw)  \n",
       "31           71   japan                    toyota corona  \n",
       "344          81     usa                   plymouth champ  \n",
       "276          78  europe                       saab 99gle  \n",
       "382          82   japan                   toyota corolla  \n",
       "200          76     usa                ford granada ghia  \n",
       "229          77     usa            pontiac grand prix lj  \n",
       "104          73     usa                     ford country  \n",
       "15           70     usa                  plymouth duster  \n",
       "66           72     usa               amc ambassador sst  \n",
       "166          75     usa                  ford mustang ii  \n",
       "109          73     usa                   chevrolet vega  \n",
       "132          74     usa                   chevrolet vega  \n",
       "154          75     usa                  mercury monarch  \n",
       "294          79   japan                 maxda glc deluxe  \n",
       "221          77     usa        chevrolet caprice classic  \n",
       "377          82   japan                 mazda glc custom  \n",
       "7            70     usa                plymouth fury iii  \n",
       "14           70   japan            toyota corona mark ii  \n",
       "237          77     usa               chevrolet chevette  \n",
       "135          74     usa       plymouth satellite sebring  \n",
       "352          81     usa                   ford escort 2h  \n",
       "13           70     usa          buick estate wagon (sw)  \n",
       "189          76     usa                      amc matador  \n",
       "263          78     usa  buick regal sport coupe (turbo)  \n",
       "80           72     usa                  ford pinto (sw)  \n",
       "282          79     usa                  ford fairmont 4  \n",
       "159          75     usa                         ford ltd  \n",
       "28           70     usa                         hi 1200d  \n",
       "78           72  europe                 peugeot 504 (sw)  \n",
       "347          81   japan                   datsun 210 mpg  \n",
       "197          76  europe                        vw rabbit  \n",
       "220          77   japan            datsun f-10 hatchback  \n",
       "79           72  europe                  renault 12 (sw)  \n",
       "37           71     usa                      amc matador  \n",
       "51           71  europe                      peugeot 304  \n",
       "139          74     usa            ford gran torino (sw)  \n",
       "361          81   japan                  toyota cressida  \n",
       "136          74     usa                 ford gran torino  \n",
       "321          80   japan                   toyota corolla  \n",
       "309          80  europe                        vw rabbit  \n",
       "239          77   japan                        subaru dl  \n",
       "162          75     usa                      amc matador  \n",
       "258          78     usa            buick century special  \n",
       "77           72  europe              volkswagen 411 (sw)  \n",
       "178          75  europe                      peugeot 504  \n",
       "181          75   japan                 honda civic cvcc  \n",
       "62           72     usa                 chevrolet impala  \n",
       "48           71     usa                     ford mustang  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Perform t`est train split\n",
    "X_train , X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Build a Ridge, Lasso and regular linear regression model. \n",
    "# Note how in scikit learn, the regularization parameter is denoted by alpha (and not lambda)\n",
    "#alpha is lambda\n",
    "ridge = Ridge(alpha=0.5)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=0.5)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpenalized Linear Regression Coefficients are:[[  2.20808547  -7.13939402  -2.81015126 -17.87830797  -3.29492493\n",
      "    7.49457216]]\n",
      "Unpenalized Linear Regression Intercept:[29.87859708]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpenalized Linear Regression Coefficients are:{}\".format(lin.coef_))\n",
    "print(\"Unpenalized Linear Regression Intercept:{}\".format(lin.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[-6.44663778 -0.         -0.         -5.97022187  0.          4.33673196]\n",
      "Lasso Linear Regression Intercept:[25.45337299]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Coefficients are:[[ -2.88789481  -4.90647118  -3.33091355 -10.34934865  -3.62543478\n",
      "    7.15870972]]\n",
      "Ridge Linear Regression Intercept:[28.87981201]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge Regression Coefficients are:{}\".format(ridge.coef_))\n",
    "print(\"Ridge Linear Regression Intercept:{}\".format(ridge.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "y_h_ridge_train = ridge.predict(X_train)\n",
    "y_h_ridge_test = ridge.predict(X_test)\n",
    "\n",
    "y_h_lasso_train = np.reshape(lasso.predict(X_train),(40,1))\n",
    "y_h_lasso_test = np.reshape(lasso.predict(X_test),(10,1))\n",
    "\n",
    "y_h_lin_train = lin.predict(X_train)\n",
    "y_h_lin_test = lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40, 1)\n",
      "(10, 1)\n"
     ]
    }
   ],
   "source": [
    "print(y_h_ridge_train.shape)\n",
    "print(y_h_ridge_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n",
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(y_h_lasso_train))\n",
    "print(type(y_h_ridge_train))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Examining the Residual for Ridge, Lasso, and Unpenalized Regression coefficients"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error Ridge Model mpg    299.782857\n",
      "dtype: float64\n",
      "Test Error Ridge Model mpg    143.516324\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Lasso Model mpg    552.923281\n",
      "dtype: float64\n",
      "Test Error Lasso Model mpg    232.995225\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Unpenalized Linear Model mpg    262.967643\n",
      "dtype: float64\n",
      "Test Error Unpenalized Linear Model mpg    166.84846\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# examine the residual sum of sq\n",
    "print('Train Error Ridge Model', np.sum((y_train - y_h_ridge_train)**2))\n",
    "print('Test Error Ridge Model', np.sum((y_test - y_h_ridge_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', np.sum((y_train - lin.predict(X_train))**2))\n",
    "print('Test Error Unpenalized Linear Model', np.sum((y_test - lin.predict(X_test))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How does Ridge and Lasso Perform in Higher Dimensional Data?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 degree polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 9)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "## try polynomial features on the regression \n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "#instantiate this class\n",
    "poly_2 = PolynomialFeatures(degree=2, interaction_only=False)\n",
    "#fit and transform the data and create a  new dataframe\n",
    "df_poly= pd.DataFrame(poly_2.fit_transform(X), columns=poly_2.get_feature_names(X.columns))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 28)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poly.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(df_poly, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Build a Ridge, Lasso and regular linear regression model. \n",
    "# Note how in scikit learn, the regularization parameter is denoted by alpha (and not lambda)\n",
    "ridge = Ridge(alpha=0.3)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=0.3)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unpenalized Linear Regression Coefficients are:[[-8.20514884e+14 -5.00671133e+01  6.89129542e+01  1.68552938e+01\n",
      "  -1.85079111e+01 -1.83749720e+02  8.57010710e+01 -9.37809158e+00\n",
      "  -4.07762747e+01  8.11794652e+01 -1.61733085e+01  8.77356153e+01\n",
      "   1.89907964e+01  6.21015193e+01 -2.95864218e+02  1.88491246e+02\n",
      "  -6.83254565e+01 -1.20995187e+02  8.48989428e+01 -9.44952865e+01\n",
      "   3.76418822e+02 -3.13284768e+02 -1.11037637e+01 -2.49900549e+02\n",
      "   2.37357044e+02  1.84059023e+02 -9.99356992e+01  2.01095575e+00]]\n",
      "Unpenalized Linear Regression Intercept:[8.20514884e+14]\n"
     ]
    }
   ],
   "source": [
    "print(\"Unpenalized Linear Regression Coefficients are:{}\".format(lin.coef_))\n",
    "print(\"Unpenalized Linear Regression Intercept:{}\".format(lin.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Lasso Regression Coefficients are:[  0.          -4.31194273  -0.19062266  -0.         -10.83142286\n",
      "   0.           0.          -0.          -0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.          -0.          -0.          -0.          -0.\n",
      "  -0.           0.           6.54287334]\n",
      "Lasso Linear Regression Intercept:[26.46586432]\n"
     ]
    }
   ],
   "source": [
    "print(\"Lasso Regression Coefficients are:{}\".format(lasso.coef_))\n",
    "print(\"Lasso Linear Regression Intercept:{}\".format(lasso.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ridge Regression Coefficients are:[[ 0.         -1.59262517 -6.00072572 -4.73086427 -7.00962244  0.03406229\n",
      "   4.03137765 -0.33172208 -0.56245817  1.62072565  3.43337507  1.63438506\n",
      "  -1.23922984 -1.05824678  0.33699903  0.01759215 -3.38978751 -3.30444291\n",
      "  -0.03628027  0.16864091 -2.68193024 -3.63942582  1.09455844 -4.62549013\n",
      "  -4.19693913 -1.91473091  2.73298831  4.3447381 ]]\n",
      "Ridge Linear Regression Intercept:[27.81872223]\n"
     ]
    }
   ],
   "source": [
    "print(\"Ridge Regression Coefficients are:{}\".format(ridge.coef_))\n",
    "print(\"Ridge Linear Regression Intercept:{}\".format(ridge.intercept_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "y_h_ridge_train = ridge.predict(X_train)\n",
    "y_h_ridge_test = ridge.predict(X_test)\n",
    "\n",
    "y_h_lasso_train = np.reshape(lasso.predict(X_train),(40,1))\n",
    "y_h_lasso_test = np.reshape(lasso.predict(X_test),(10,1))\n",
    "\n",
    "y_h_lin_train = lin.predict(X_train)\n",
    "y_h_lin_test = lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error Ridge Model mpg    146.650875\n",
      "dtype: float64\n",
      "Test Error Ridge Model mpg    138.360675\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Lasso Model mpg    363.48172\n",
      "dtype: float64\n",
      "Test Error Lasso Model mpg    167.15797\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Unpenalized Linear Model mpg    1159.804375\n",
      "dtype: float64\n",
      "Test Error Unpenalized Linear Model mpg    6993.84375\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# examine the residual sum of sq\n",
    "print('Train Error Ridge Model', np.sum((y_train - y_h_ridge_train)**2))\n",
    "print('Test Error Ridge Model', np.sum((y_test - y_h_ridge_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', np.sum((y_train - lin.predict(X_train))**2))\n",
    "print('Test Error Unpenalized Linear Model', np.sum((y_test - lin.predict(X_test))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Even higher degree polynomials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50, 462)"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "poly_5 = PolynomialFeatures(degree=5, interaction_only=False)\n",
    "#fit and transform the data and create a  new dataframe\n",
    "df_poly_5= pd.DataFrame(poly_5.fit_transform(X), columns=poly_5.get_feature_names(X.columns))\n",
    "df_poly_5.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None, normalize=False)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train , X_test, y_train, y_test = train_test_split(df_poly_5, y, test_size=0.2, random_state=12)\n",
    "\n",
    "# Build a Ridge, Lasso and regular linear regression model. \n",
    "# Note how in scikit learn, the regularization parameter is denoted by alpha (and not lambda)\n",
    "ridge = Ridge(alpha=1)\n",
    "ridge.fit(X_train, y_train)\n",
    "\n",
    "lasso = Lasso(alpha=1)\n",
    "lasso.fit(X_train, y_train)\n",
    "\n",
    "lin = LinearRegression()\n",
    "lin.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create predictions\n",
    "y_h_ridge_train = ridge.predict(X_train)\n",
    "y_h_ridge_test = ridge.predict(X_test)\n",
    "\n",
    "y_h_lasso_train = np.reshape(lasso.predict(X_train),(40,1))\n",
    "y_h_lasso_test = np.reshape(lasso.predict(X_test),(10,1))\n",
    "\n",
    "y_h_lin_train = lin.predict(X_train)\n",
    "y_h_lin_test = lin.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Error Ridge Model mpg    209.196038\n",
      "dtype: float64\n",
      "Test Error Ridge Model mpg    95.551673\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Lasso Model mpg    1056.642075\n",
      "dtype: float64\n",
      "Test Error Lasso Model mpg    182.885436\n",
      "dtype: float64\n",
      "\n",
      "\n",
      "Train Error Unpenalized Linear Model mpg    7.860652e-25\n",
      "dtype: float64\n",
      "Test Error Unpenalized Linear Model mpg    1783.897995\n",
      "dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# examine the residual sum of sq\n",
    "print('Train Error Ridge Model', np.sum((y_train - y_h_ridge_train)**2))\n",
    "print('Test Error Ridge Model', np.sum((y_test - y_h_ridge_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Lasso Model', np.sum((y_train - y_h_lasso_train)**2))\n",
    "print('Test Error Lasso Model', np.sum((y_test - y_h_lasso_test)**2))\n",
    "print('\\n')\n",
    "\n",
    "print('Train Error Unpenalized Linear Model', np.sum((y_train - lin.predict(X_train))**2))\n",
    "print('Test Error Unpenalized Linear Model', np.sum((y_test - lin.predict(X_test))**2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calculating AIC and BIC \n",
    "AIC and BIC are information criteria for evaluating how good of a model is by giving a measurement of parsimony and goodness of fit. \n",
    "\n",
    "- AIC is defined as: $2k - 2log(L)$\n",
    "- BIC is defined as: $klog(n) - 2log(L)$  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "def aic(y, y_pred, k):\n",
    "    resid = y - y_pred\n",
    "    sse = (resid**2).sum()\n",
    "    AIC = 2*k - 2*np.log(sse)\n",
    "    \n",
    "    return AIC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "462"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_poly_5.shape[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg    910.373115\n",
       "dtype: float64"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic(y_test, y_h_lasso_test, df_poly_5.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg    912.312082\n",
       "dtype: float64"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic(y_test, y_h_ridge_test, df_poly_5.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mpg    909.490627\n",
       "dtype: float64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "aic(y_test, y_h_lin_test, df_poly_5.shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
